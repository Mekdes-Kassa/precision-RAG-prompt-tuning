{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    openai_api_key=openai_key, \n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='String theory is a theoretical framework in physics that aims to explain the fundamental nature of matter and the forces that govern it. It suggests that instead of particles being point-like, they are actually tiny, vibrating strings. These strings can vibrate in different modes, and each mode corresponds to a different particle with specific properties such as mass and charge.\\n\\nOne of the key features of string theory is that it attempts to unify all the known fundamental forces of nature: gravity, electromagnetism, and the strong and weak nuclear forces. It suggests that these forces are all different manifestations of the vibrations of these tiny strings.\\n\\nString theory also proposes the existence of additional dimensions beyond the three spatial dimensions (length, width, and height) that we are familiar with. These extra dimensions, if they exist, are believed to be curled up and too small to be detected directly.\\n\\nIt is important to note that string theory is still a highly active area of research, and many aspects of it are not yet fully understood. However, it offers a promising framework for understanding the fundamental nature of the universe and has the potential to reconcile quantum mechanics with general relativity.\\n\\nDo you have any specific questions about string theory?', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physicists believe that string theory has the potential to produce a unified theory because it incorporates all the fundamental forces of nature within a single framework. In other words, it aims to provide a consistent description of how gravity, electromagnetism, and the strong and weak nuclear forces are connected and operate at a fundamental level.\n",
      "\n",
      "One of the main motivations for seeking a unified theory is the desire to resolve the incompatibility between quantum mechanics, which describes the behavior of particles on very small scales, and general relativity, which describes the behavior of gravity on large scales. These two theories are extremely successful in their respective domains, but they have different mathematical formulations and cannot be easily combined.\n",
      "\n",
      "String theory offers a potential solution by replacing point-like particles with tiny, vibrating strings. This fundamentally different approach allows for the possibility of unifying the forces of nature. The vibrations of these strings can give rise to different particles, including those associated with gravity, electromagnetism, and the nuclear forces.\n",
      "\n",
      "Furthermore, string theory also predicts the existence of additional dimensions beyond the three spatial dimensions we experience. These extra dimensions can help reconcile the different forces by providing a geometric framework in which they can interact and unify.\n",
      "\n",
      "While string theory is still a work in progress and many details are yet to be fully understood, it provides a promising framework for potentially achieving a unified theory that can explain all the fundamental forces and particles in the universe.\n"
     ]
    }
   ],
   "source": [
    "# add latest AI response to messages\n",
    "messages.append(res)\n",
    "\n",
    "# now create a new user prompt\n",
    "prompt = HumanMessage(\n",
    "    content=\"Why do physicists believe it can produce a 'unified theory'?\"\n",
    ")\n",
    "# add to messages\n",
    "messages.append(prompt)\n",
    "\n",
    "# send to chat-gpt\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the challenge document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Open the PDF file in binary read mode\n",
    "with open(\"/home/hp/Documents/week 5/precision-RAG-prompt-tuning/prompt_generation_system/10 Academy Cohort A - Weekly Challenge Week - 6.pdf\", \"rb\") as file:\n",
    "    # Create a PDF reader object\n",
    "    pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "\n",
    "    for page in range(num_pages):\n",
    "        page_obj = pdf_reader.pages[page]\n",
    "        extracted_text = page_obj.extract_text()\n",
    "        \n",
    "len(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: References\n",
      "●\n",
      "Meistrari\n",
      "didn’t\n",
      "see\n",
      "a\n",
      "good\n",
      "solution\n",
      "\n",
      "Chunk 2: see\n",
      "a\n",
      "good\n",
      "solution\n",
      "for\n",
      "prompt\n",
      "engineering,\n",
      "so\n",
      "it’\n",
      "Chunk 3: \n",
      "engineering,\n",
      "so\n",
      "it’s\n",
      "building\n",
      "one\n",
      "●\n",
      "AutoPrompt:\n",
      "E\n",
      "Chunk 4: \n",
      "one\n",
      "●\n",
      "AutoPrompt:\n",
      "Eliciting\n",
      "Knowledge\n",
      "from\n",
      "Langua\n",
      "Chunk 5: nowledge\n",
      "from\n",
      "Language\n",
      "Models\n",
      "with\n",
      "Automatically\n",
      "G\n",
      "Chunk 6: with\n",
      "Automatically\n",
      "Generated\n",
      "Prompts\n",
      "●\n",
      "Large\n",
      "Langu\n",
      "Chunk 7: rompts\n",
      "●\n",
      "Large\n",
      "Language\n",
      "Models\n",
      "Are\n",
      "Human-Level\n",
      "Pro\n",
      "Chunk 8: \n",
      "Are\n",
      "Human-Level\n",
      "Prompt\n",
      "Engineers\n",
      "●\n",
      "Prompt\n",
      "Enginee\n",
      "Chunk 9: ers\n",
      "●\n",
      "Prompt\n",
      "Engineering\n",
      "●\n",
      "How\n",
      "to\n",
      "Create\n",
      "a\n",
      "Monte\n",
      "C\n",
      "Chunk 10: \n",
      "to\n",
      "Create\n",
      "a\n",
      "Monte\n",
      "Carlo\n",
      "Simulation\n",
      "using\n",
      "Python\n",
      "●\n",
      "Chunk 11: ation\n",
      "using\n",
      "Python\n",
      "●\n",
      "Monte\n",
      "Carlo\n",
      "Method\n",
      "Explained\n",
      "\n",
      "Chunk 12: lo\n",
      "Method\n",
      "Explained\n",
      "●\n",
      "What\n",
      "is\n",
      "Monte\n",
      "Carlo\n",
      "Simulati\n",
      "Chunk 13: Monte\n",
      "Carlo\n",
      "Simulation?\n",
      "How\n",
      "does\n",
      "it\n",
      "work?\n",
      "●\n",
      "Elo\n",
      "Ra\n",
      "Chunk 14: es\n",
      "it\n",
      "work?\n",
      "●\n",
      "Elo\n",
      "Rating\n",
      "Algorithm\n",
      "●\n",
      "Elo\n",
      "algorithm\n",
      "Chunk 15: ithm\n",
      "●\n",
      "Elo\n",
      "algorithm\n",
      "implementation\n",
      "in\n",
      "Python\n",
      "●\n",
      "Tr\n",
      "Chunk 16: ation\n",
      "in\n",
      "Python\n",
      "●\n",
      "TrueSkillTM:\n",
      "A\n",
      "Bayesian\n",
      "skill\n",
      "ra\n",
      "Chunk 17: \n",
      "A\n",
      "Bayesian\n",
      "skill\n",
      "rating\n",
      "system\n",
      "Chunk 18: m\n"
     ]
    }
   ],
   "source": [
    "chunk_size=50\n",
    "overlap=20\n",
    "def chunk_text(extracted_text, chunk_size, overlap):\n",
    "    chunks = []\n",
    "    text_length = len(extracted_text)\n",
    "\n",
    "    for start in range(0, text_length, chunk_size - overlap):\n",
    "        end = min(start + chunk_size, text_length)\n",
    "        chunk = extracted_text[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(extracted_text, chunk_size, overlap)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = chunk_text(extracted_text, chunk_size, overlap)\n",
    "\n",
    "#for i, chunk in enumerate(chunks):\n",
    "    #print(f\"Chunk {i + 1}:\", chunk)\n",
    "type(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize the client and connect to the targetted index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26b33591-e6c6-499a-b91a-37c5f40265df\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pinecone' has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(api_key)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize Pinecone with the API key\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create or connect to the 'quickstart' index\u001b[39;00m\n\u001b[1;32m      9\u001b[0m index \u001b[38;5;241m=\u001b[39m pinecone\u001b[38;5;241m.\u001b[39mIndex(index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmekdes-index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pinecone' has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "api_key = os.getenv(\"api_keyy\")\n",
    "print(api_key)\n",
    "# Initialize Pinecone with the API key\n",
    "pinecone.init(api_key=api_key)\n",
    "\n",
    "# Create or connect to the 'quickstart' index\n",
    "index = pinecone.Index(index_name=\"mekdes-index\")\n",
    "# get API key from app.pinecone.io and environment from console\n",
    "pinecone.init(\n",
    "    api_key=api_key,\n",
    "    environment='gcp-starter'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26b33591-e6c6-499a-b91a-37c5f40265df\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pinecone' has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(api_key)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize Pinecone with the API key\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mpinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create or connect to the 'quickstart' index\u001b[39;00m\n\u001b[1;32m     11\u001b[0m index \u001b[38;5;241m=\u001b[39m pinecone\u001b[38;5;241m.\u001b[39mIndex(index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmekdes-index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pinecone' has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "api_key = os.getenv(\"api_key\")\n",
    "print(api_key)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.12' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "index.describe_index_stats('mekdes-index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embed and add chunks to pinecone index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.12' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Function to embed and add chunks to Pinecone index\n",
    "def embed_and_add_to_pinecone(chunks, index_name):\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        def embedding_function(text_chunk):\n",
    "            # Load the pre-trained Universal Sentence Encoder model\n",
    "            embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "            # Embed the text chunk\n",
    "            embedded_chunk = embed([text_chunk])[0].numpy().tolist()\n",
    "\n",
    "            return embedded_chunk\n",
    "\n",
    "        # Embed each chunk using your embedding method (not specified in the question)\n",
    "        # Replace 'embedding_function' with the actual function you use for embedding\n",
    "        embedding = embedding_function(chunk)\n",
    "\n",
    "        # Add the embedded chunk to the Pinecone index using upsert\n",
    "        pinecone.upsert(index_name, [{'id': str(i), 'vector': embedding}])\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.12' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "chunks = [\"This is a sample text.\", \"Another example sentence.\"]\n",
    "index_name = \"your_index_name\"\n",
    "\n",
    "# Embed and add chunks to Pinecone\n",
    "embed_and_add_to_pinecone(chunks, index_name)\n",
    "\n",
    "# Close Pinecone connection\n",
    "pinecone.deinit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.12' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.12' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load a pre-trained Word2Vec model (download and load your specific model)\n",
    "# For example, you might use a model trained on a large text corpus\n",
    "# This is just a placeholder, and you need to replace it with your actual model loading logic\n",
    "word2vec_model = Word2Vec.load(\"path/to/your/word2vec_model\")\n",
    "\n",
    "def embed_function(chunk):\n",
    "    # Tokenize the text (replace this with the appropriate tokenization for your data)\n",
    "    tokens = word_tokenize(chunk.lower())\n",
    "    \n",
    "    # Embed each token and calculate the average vector as the representation of the chunk\n",
    "    vectors = [word2vec_model.wv[token] for token in tokens if token in word2vec_model.wv]\n",
    "    \n",
    "    if vectors:\n",
    "        # Calculate the average vector\n",
    "        average_vector = sum(vectors) / len(vectors)\n",
    "        return average_vector\n",
    "    else:\n",
    "        # Return a placeholder vector if no valid tokens are found\n",
    "        return [0.0] * word2vec_model.vector_size\n",
    "\n",
    "# Example usage:\n",
    "chunk_data = [\"This is a sample text.\", \"Another example sentence.\"]\n",
    "chunk_ids = [1, 2]\n",
    "\n",
    "vectors = [embed_function(chunk) for chunk in chunk_data]\n",
    "\n",
    "# Assuming you already created a Pinecone index named 'your_index_name'\n",
    "index.upsert(ids=chunk_ids, vectors=vectors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
